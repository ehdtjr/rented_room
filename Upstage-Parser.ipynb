{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 파싱을 위한 필수 라이브러리들을 임포트합니다\n",
    "import os\n",
    "from layoutparse.utils import (\n",
    "    SplitPDFFilesNode,\n",
    ")  # PDF 파일을 분할하는 노드를 임포트합니다\n",
    "from layoutparse.state import ParseState  # 파싱 상태를 관리하는 클래스를 임포트합니다\n",
    "from layoutparse.upstage import (  # Upstage 관련 주요 노드들을 임포트합니다\n",
    "    DocumentParseNode,  # 문서 파싱을 담당하는 노드\n",
    "    PostDocumentParseNode,  # 파싱 후처리를 담당하는 노드\n",
    "    WorkingQueueNode,  # 작업 큐를 관리하는 노드\n",
    "    continue_parse,  # 파싱 계속 여부를 결정하는 함수\n",
    ")\n",
    "from langgraph.graph import StateGraph  # 그래프 상태를 관리하는 클래스를 임포트합니다\n",
    "from langgraph.checkpoint.memory import (\n",
    "    MemorySaver,\n",
    ")  # 메모리 체크포인트 저장을 위한 클래스입니다\n",
    "from langchain_teddynote.graphs import (\n",
    "    visualize_graph,\n",
    ")  # 그래프 시각화를 위한 함수를 임포트합니다\n",
    "\n",
    "\n",
    "# PDF 파일을 30페이지 단위로 분할하는 노드를 생성합니다\n",
    "# verbose=True로 설정하면 노드의 실행 상태를 출력합니다\n",
    "split_pdf_node = SplitPDFFilesNode(batch_size=30, test_page=None, verbose=True)\n",
    "\n",
    "# Upstage API를 사용하여 문서를 파싱하는 노드를 생성합니다\n",
    "document_parse_node = DocumentParseNode(\n",
    "    api_key=os.environ[\"UPSTAGE_API_KEY\"],use_ocr=True, verbose=True\n",
    ")\n",
    "\n",
    "# 파싱 후처리를 담당하는 노드를 생성합니다\n",
    "post_document_parse_node = PostDocumentParseNode(verbose=True)\n",
    "# 작업 큐를 관리하는 노드를 생성합니다\n",
    "working_queue_node = WorkingQueueNode(verbose=True)\n",
    "\n",
    "\n",
    "# ParseState를 기반으로 하는 StateGraph 워크플로우를 생성합니다\n",
    "workflow = StateGraph(ParseState)\n",
    "\n",
    "# 워크플로우에 각각의 노드들을 추가합니다\n",
    "workflow.add_node(\"split_pdf_node\", split_pdf_node)\n",
    "workflow.add_node(\"document_parse_node\", document_parse_node)\n",
    "workflow.add_node(\"post_document_parse_node\", post_document_parse_node)\n",
    "workflow.add_node(\"working_queue_node\", working_queue_node)\n",
    "\n",
    "# 노드들 간의 연결 관계를 설정합니다\n",
    "workflow.add_edge(\"split_pdf_node\", \"working_queue_node\")\n",
    "# 작업 큐 노드에서 조건에 따라 다음 노드를 결정하는 분기를 추가합니다\n",
    "workflow.add_conditional_edges(\n",
    "    \"working_queue_node\",\n",
    "    continue_parse,\n",
    "    {True: \"document_parse_node\", False: \"post_document_parse_node\"},\n",
    ")\n",
    "workflow.add_edge(\"document_parse_node\", \"working_queue_node\")\n",
    "\n",
    "# 워크플로우의 시작점을 PDF 분할 노드로 설정합니다\n",
    "workflow.set_entry_point(\"split_pdf_node\")\n",
    "\n",
    "# 최종적으로 메모리 체크포인터를 사용하여 워크플로우를 컴파일합니다\n",
    "document_parse_graph = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프를 시각화합니다\n",
    "visualize_graph(document_parse_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import stream_graph\n",
    "import uuid\n",
    "\n",
    "\"\"\"\n",
    "RunnableConfig를 사용하여 그래프 실행에 필요한 설정을 정의합니다.\n",
    "recursion_limit: 재귀 호출의 제한을 설정하여 무한 루프를 방지합니다\n",
    "configurable: 실행 시 필요한 설정값들을 정의합니다\n",
    "\"\"\"\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=300,  # 재귀 호출 제한을 300으로 설정합니다\n",
    "    configurable={\"thread_id\": str(uuid.uuid4())},\n",
    ")\n",
    "\n",
    "# ParseState 객체를 생성하여 PDF 파일 처리를 위한 초기 상태를 설정합니다\n",
    "inputs = ParseState(\n",
    "    filepath=\"data/test_data.pdf\",  # 처리할 PDF 파일의 경로를 지정합니다\n",
    "    language=\"English\",  # 문서의 언어를 영어로 설정합니다\n",
    ")\n",
    "\n",
    "# 그래프를 스트리밍 모드로 실행하여 실시간으로 처리 상태를 확인합니다\n",
    "stream_graph(\n",
    "    document_parse_graph,\n",
    "    inputs,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 결과\n",
    "snapshot = document_parse_graph.get_state(config).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot[\"elements_from_parser\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layoutparse.teddynote_parser import create_upstage_parser_graph\n",
    "\n",
    "# 그래프 생성\n",
    "upstage_parser_graph = create_upstage_parser_graph(\n",
    "    batch_size=30, test_page=None, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "# 옵션 설정\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=300,\n",
    "    configurable={\"thread_id\": str(uuid.uuid4())},\n",
    ")\n",
    "\n",
    "# filepath: 분석할 PDF 파일의 경로\n",
    "inputs = {\n",
    "    \"filepath\": \"data/argus-bitumen.pdf\",\n",
    "}\n",
    "\n",
    "stream_graph(upstage_parser_graph, inputs, config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
